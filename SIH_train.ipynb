{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Gfr8jaznfK9-"},"outputs":[],"source":["from google.colab import drive\n","\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G0ahr07lzvel","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650564761872,"user_tz":-330,"elapsed":3736,"user":{"displayName":"20G022 DILLI B","userId":"08651391535401149553"}},"outputId":"ed43b2b3-0c15-4544-ce23-37c8cecfd2ab"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.1.1)\n"]}],"source":["!pip install torch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7njEp5kxzx28"},"outputs":[],"source":["import torch  "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1650564769033,"user":{"displayName":"20G022 DILLI B","userId":"08651391535401149553"},"user_tz":-330},"id":"XLmrOVeO0bJ1","outputId":"20fee8b9-8f17-4f24-a367-380e0341ebce"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/SIH Plastic Classification/yolov5/yolov5\n"]}],"source":["\n","%cd /content/drive/MyDrive/SIH Plastic Classification/yolov5/yolov5"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"NYrl6ZHg0lqV"},"outputs":[],"source":["\n","import os\n","from random import choice\n","import shutil\n","\n","# #arrays to store file names\n","# imgs =[]\n","# xmls =[]\n","\n","# #setup dir names\n","# trainPath = '/content/drive/MyDrive/SIH_Plastic_Classification/Dataset_WaDaBa_YOLO/images/train'\n","# valPath = '/content/drive/MyDrive/SIH_Plastic_Classification/Dataset_WaDaBa_YOLO/images/test'\n","# crsPath = 'D:/yolov5_traffic_sign_detection/data/ts/' #dir where images and annotations stored\n","\n","\n","source_folder = r\"/content/drive/MyDrive/SIH_Plastic_Classification/Dataset_WaDaBa_YOLO/labels//\"\n","destination_folder = r\"/content/drive/MyDrive/SIH_Plastic_Classification/Dataset_WaDaBa_YOLO/images//\"\n","\n","# fetch all files\n","for file_name in os.listdir(source_folder):\n","    # construct full file path\n","    source = source_folder + file_name\n","    destination = destination_folder + file_name\n","    # move only files\n","    if os.path.isfile(source):\n","        shutil.move(source, destination)\n","        print('Moved:', file_name)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3870,"status":"ok","timestamp":1650564830648,"user":{"displayName":"20G022 DILLI B","userId":"08651391535401149553"},"user_tz":-330},"id":"GFQP40u30nau","outputId":"32894197-91db-4c9a-d264-034d7a7fd92b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (3.2.2)\n","Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (1.21.6)\n","Requirement already satisfied: opencv-python>=4.1.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (4.1.2.30)\n","Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (7.1.2)\n","Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (6.0)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (2.23.0)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (1.4.1)\n","Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (1.10.0+cu111)\n","Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (0.11.1+cu111)\n","Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 13)) (4.64.0)\n","Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 16)) (2.8.0)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 20)) (1.3.5)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 21)) (0.11.2)\n","Requirement already satisfied: thop in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 37)) (0.0.31.post2005241907)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (1.4.2)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (3.0.8)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (2.8.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (0.11.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (1.24.3)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.7.0->-r requirements.txt (line 11)) (4.1.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.35.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.8.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.0.1)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.44.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (0.37.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (3.3.6)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.0.0)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (57.4.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (0.4.6)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (0.6.1)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (3.17.3)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 20)) (2022.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.15.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 16)) (4.8)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 16)) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 16)) (4.2.4)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 16)) (4.11.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 16)) (3.8.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 16)) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 16)) (3.2.0)\n"]}],"source":["!pip install -r requirements.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"R00HtoJYaUCX"},"outputs":[],"source":["import sys\n","\n","sys.path.append('PATH_TO_TENSORFLOW_OBJECT_DETECTION_FOLDER')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zvsPsShX0qBY","outputId":"029f384f-cbde-413f-8258-bf474b6efe13"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n","\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=30, batch_size=3, imgsz=400, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n","Command 'git fetch && git config --get remote.origin.url' timed out after 5 seconds\n","remote: Enumerating objects: 19, done.\u001b[K\n","remote: Counting objects: 100% (19/19), done.\u001b[K\n","remote: Compressing objects: 100% (10/10), done.\u001b[K\n","remote: Total 19 (delta 9), reused 18 (delta 9), pack-reused 0\u001b[K\n","Unpacking objects: 100% (19/19), done.\n","fatal: cannot change to '/content/drive/MyDrive/SIH': No such file or directory\n","YOLOv5 🚀 2022-4-17 torch 1.10.0+cu111 CUDA:0 (Tesla K80, 11441MiB)\n","\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n","\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 🚀 runs (RECOMMENDED)\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n","From https://github.com/ultralytics/yolov5\n","   f9aa765..0d28bf0  test/conv_reduction -> origin/test/conv_reduction\n","Overriding model.yaml nc=80 with nc=5\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n","  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n","  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n","  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n","  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n","  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n","  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n","  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n","  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n"," 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n"," 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n"," 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n"," 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n"," 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n"," 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n"," 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n"," 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n"," 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n"," 24      [17, 20, 23]  1     26970  models.yolo.Detect                      [5, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n","Model summary: 270 layers, 7033114 parameters, 7033114 gradients, 15.9 GFLOPs\n","\n","Transferred 343/349 items from yolov5s.pt\n","WARNING: --img-size 400 must be multiple of max stride 32, updating to 416\n","Scaled weight_decay = 0.0004921875\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n","\u001b[34m\u001b[1malbumentations: \u001b[0mversion 1.0.3 required by YOLOv5, but version 0.1.12 is currently installed\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/drive/MyDrive/SIH Plastic Classification/yolov5/yolov5/data/WaDaBa/train/labels.cache' images and labels... 4365 found, 5 missing, 0 empty, 0 corrupt: 100% 4370/4370 [00:00<?, ?it/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (1.5GB ram): 100% 4370/4370 [07:13<00:00, 10.07it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/drive/MyDrive/SIH Plastic Classification/yolov5/yolov5/data/WaDaBa/test/labels.cache' images and labels... 342 found, 0 missing, 0 empty, 0 corrupt: 100% 342/342 [00:00<?, ?it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB ram): 100% 342/342 [00:29<00:00, 11.63it/s]\n","Plotting labels to runs/train/exp7/labels.jpg... \n","\n","\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.08 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n","Image sizes 416 train, 416 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1mruns/train/exp7\u001b[0m\n","Starting training for 30 epochs...\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      0/29    0.365G   0.05678    0.0192   0.03525         4       416: 100% 1457/1457 [04:48<00:00,  5.06it/s]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 57/57 [00:04<00:00, 13.22it/s]\n","                 all        342        342      0.442      0.676      0.462      0.171\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      1/29    0.365G   0.04135   0.01243   0.02201         5       416: 100% 1457/1457 [04:36<00:00,  5.26it/s]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 57/57 [00:04<00:00, 13.43it/s]\n","                 all        342        342      0.633      0.567      0.562      0.365\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      2/29    0.367G   0.03788   0.01128   0.01915         5       416: 100% 1457/1457 [04:32<00:00,  5.34it/s]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 57/57 [00:04<00:00, 13.48it/s]\n","                 all        342        342      0.762      0.615      0.585      0.345\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      3/29    0.367G   0.03317   0.01109   0.01857         3       416: 100% 1457/1457 [04:32<00:00,  5.35it/s]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 57/57 [00:04<00:00, 13.41it/s]\n","                 all        342        342      0.737      0.721      0.635      0.453\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      4/29    0.367G   0.02968   0.01051   0.01655         4       416: 100% 1457/1457 [04:31<00:00,  5.36it/s]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 57/57 [00:04<00:00, 13.58it/s]\n","                 all        342        342      0.745      0.767      0.653      0.488\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      5/29    0.367G   0.02746   0.01012   0.01478         4       416: 100% 1457/1457 [04:34<00:00,  5.31it/s]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 57/57 [00:04<00:00, 13.57it/s]\n","                 all        342        342      0.812       0.72       0.69      0.523\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      6/29    0.367G   0.02669  0.009906    0.0139         6       416: 100% 1457/1457 [04:33<00:00,  5.33it/s]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 57/57 [00:04<00:00, 13.45it/s]\n","                 all        342        342      0.794      0.746      0.767      0.575\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      7/29    0.367G   0.02552   0.00971   0.01339         2       416: 100% 1457/1457 [04:32<00:00,  5.34it/s]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 57/57 [00:04<00:00, 13.43it/s]\n","                 all        342        342      0.811      0.747      0.759      0.583\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      8/29    0.367G    0.0246  0.009477   0.01347        11       416:  35% 508/1457 [01:34<02:55,  5.41it/s]"]}],"source":["\n","!python train.py --img 400 --batch 1 --epochs 15 --data data.yaml --weights yolov5s.pt --cache"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":0,"status":"ok","timestamp":1650548326870,"user":{"displayName":"20G022 DILLI B","userId":"08651391535401149553"},"user_tz":-330},"id":"Lj1oVuG60usq","outputId":"e5f6871f-75fc-42c8-8ef7-5424ef74851c"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/SIH Plastic Classification/yolov5\n","fatal: destination path 'yolor' already exists and is not an empty directory.\n"]}],"source":["\n","%cd /content/drive/MyDrive/SIH Plastic Classification/yolov5\n","!git clone https://github.com/WongKinYiu/yolor.git"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1482,"status":"ok","timestamp":1650186370234,"user":{"displayName":"20G022 DILLI B","userId":"08651391535401149553"},"user_tz":-330},"id":"kdv4KrNWahyA","outputId":"1564c227-9edc-4e5f-c42d-5ceff986da02"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/SIH Plastic Classification/yolov5/yolor\n"]}],"source":["%cd yolor"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5362,"status":"ok","timestamp":1650186649630,"user":{"displayName":"20G022 DILLI B","userId":"08651391535401149553"},"user_tz":-330},"id":"Bc8JW9UuxZ69","outputId":"a19c548c-c847-4cb8-b081-d0f1b3d942a6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using torch 1.10.0+cu111 CUDA:0 (Tesla T4, 15109MB)\n","\n","Namespace(adam=False, batch_size=64, bucket='', cache_images=True, cfg='', data='./data/data.yaml', device='', epochs=30, evolve=False, exist_ok=False, global_rank=-1, hyp='data/hyp.scratch.1280.yaml', image_weights=False, img_size=[415, 415], local_rank=-1, log_imgs=16, multi_scale=False, name='exp', noautoanchor=False, nosave=False, notest=False, project='runs/train', rect=False, resume=False, save_dir='runs/train/exp2', single_cls=False, sync_bn=False, total_batch_size=64, weights='yolor_p6.pt', workers=8, world_size=1)\n","Start Tensorboard with \"tensorboard --logdir runs/train\", view at http://localhost:6006/\n","Hyperparameters {'lr0': 0.01, 'lrf': 0.2, 'momentum': 0.937, 'weight_decay': 0.0005, 'warmup_epochs': 3.0, 'warmup_momentum': 0.8, 'warmup_bias_lr': 0.1, 'box': 0.05, 'cls': 0.5, 'cls_pw': 1.0, 'obj': 1.0, 'obj_pw': 1.0, 'iou_t': 0.2, 'anchor_t': 4.0, 'fl_gamma': 0.0, 'hsv_h': 0.015, 'hsv_s': 0.7, 'hsv_v': 0.4, 'degrees': 0.0, 'translate': 0.5, 'scale': 0.5, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.5, 'mosaic': 1.0, 'mixup': 0.0}\n","Downloading https://github.com/WongKinYiu/yolor/releases/download/v1.0/yolor_p6.pt to yolor_p6.pt...\n","ERROR: Download failure.\n","\n","Traceback (most recent call last):\n","  File \"train.py\", line 537, in <module>\n","    train(hyp, opt, device, tb_writer, wandb)\n","  File \"train.py\", line 80, in train\n","    ckpt = torch.load(weights, map_location=device)  # load checkpoint\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 594, in load\n","    with _open_file_like(f, 'rb') as opened_file:\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 230, in _open_file_like\n","    return _open_file(name_or_buffer, mode)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 211, in __init__\n","    super(_open_file, self).__init__(open(name, mode))\n","FileNotFoundError: [Errno 2] No such file or directory: 'yolor_p6.pt'\n"]}],"source":["\n","!python train.py --img 415 --batch 64 --epochs 30 --data data.yaml --weights yolor_p6.pt --cache"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wKzTiH7mx0vX"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"name":"SIH_train.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}